{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- for final presentation, maybe mention development date for algorithms ? \n",
    "\n",
    "TODO:\n",
    "- update performance conclusion automatically\n",
    "- figure out inputing one \"row\" & predict ourcome (as if user info is predicted)\n",
    "- it works with features_test; but not with test_row  => figure out what type test_row needs to be\n",
    "- why is prediction accuracy 100% for some models? Not good (maybe fixed after manual prediction works?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[0],axis = 1)\n",
    "\n",
    "# remove colums containing NaN values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "df.set_axis(range(len(df)), inplace=True)\n",
    "\n",
    "# print(\"No. of columns containing null values\")\n",
    "# print(len(df.columns[df.isna().any()]))\n",
    "\n",
    "# print(\"No. of columns not containing null values\")\n",
    "# print(len(df.columns[df.notna().all()]))\n",
    "\n",
    "# print(\"Total no. of columns in the dataframe\")\n",
    "# print(len(df.columns))s\n",
    "\n",
    "# removing target('diabetes') from features\n",
    "target = df['diabetes']\n",
    "features = df.drop(['diabetes'],axis=1)\n",
    "\n",
    "# splitting into training and test data\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(features_train.shape)\n",
    "# print(features_test.shape)\n",
    "# print(target_train.shape)\n",
    "# print(target_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 100\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    print(max_iter)\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    # svm_classifier = svm.SVC(kernel = \"linear\", max_iter = max_iter)\n",
    "    svm_predictions = svm_classifier.predict(features_test)\n",
    "    svm_accuracy = accuracy_score(target_test, svm_predictions)\n",
    "\n",
    "    print(f\"Accuracy : {100 * svm_accuracy}\")\n",
    "    return {'loss': - svm_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution od 1 & 0 on test data\n",
    "print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_iter = 32\n",
    "svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(svm_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = svm_classifier.predict(test_row)\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(svm_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "\n",
    "- simple SVM: Best reachable Accuracy: 86.80559 %, with max_iter= 36\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy: 99.66852863544289%, with max_iter = 93"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Stocastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 100\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    print(max_iter)\n",
    "    # sgd_classifier = make_pipeline(StandardScaler(), SGDClassifier(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    sgd_classifier = SGDClassifier(max_iter = max_iter).fit(features_train, target_train)\n",
    "    sgd_predictions = sgd_classifier.predict(features_test)\n",
    "    sgd_accuracy = accuracy_score(target_test, sgd_predictions)\n",
    "\n",
    "    print(f\"Accuracy : {100 * sgd_accuracy}\")\n",
    "    return {'loss': - sgd_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution od 1 & 0 on test data\n",
    "print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_iter = 32\n",
    "sgd_classifier = SGDClassifier(max_iter = max_iter).fit(features_train, target_train)\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgd_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgd_classifier.predict(test_row)\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgd_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- simple SGD: Best reachable Accuracy:  87.33042784359463%, with max_iter= 74\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  100%, with max_iter = 11 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Stocastic Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_depth to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 100\n",
    "SEARCH_SPACE = [hp.randint('max_depth',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_depth):\n",
    "    max_depth = max_depth[0]\n",
    "    if max_depth == 0:\n",
    "        return 0\n",
    "    print(max_depth)\n",
    "    # sgb_classifier = make_pipeline(StandardScaler(), sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth, random_stat=0).fit(features_train, target_train)\n",
    "    sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth).fit(features_train, target_train)    \n",
    "    sgb_predictions = sgb_classifier.predict(features_test)\n",
    "    sgb_accuracy = accuracy_score(target_test, sgb_predictions)\n",
    "    comp = target_test == sgb_predictions\n",
    "    print(Counter(comp))\n",
    "    print(f\"Accuracy : {100 * sgb_accuracy}\")\n",
    "    return {'loss': - sgb_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' with previously determined max_iter #################################################################################################\n",
    "\n",
    "# see distribution od 1 & 0 on test data\n",
    "print(Counter(target_test))\n",
    "\n",
    "# change to automatically get best max_iter & fill in here! TODO\n",
    "max_depth = 32\n",
    "sgb_classifier = GradientBoostingClassifier(n_estimators=10, learning_rate=0.5, max_depth=max_depth).fit(features_train, target_train)    \n",
    "\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgb_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgb_classifier.predict(test_row)\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgb_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)\n",
    "\n",
    "# bzw: what type of input needs test_row to be?!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- simple SGB: Best reachable Accuracy:  87.33042784359463%, with max_iter= 74\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  100%, with max_iter = 11 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f891c0ef62455f9f8d0cbb2d117bcba51effc94d210f58e83104cbf88b6bc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
