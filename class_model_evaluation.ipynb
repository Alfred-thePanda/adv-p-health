{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- for final presentation, maybe mention development date for algorithms \n",
    "- visualisierung fÃ¼r probierte werte \n",
    "- vergleichbare projekte von anderen + deren reached accuracy ( zum vergleich, um zu beweisen, dass unsere gut?)\n",
    "- evtl nur max iter 200 - 400 testen oder so + cast to int "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **0. Data Prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/brfss_wo_null.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 324770, 1.0: 53110})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *Ever told you had diabetes*\n",
    "print(Counter(df['DIABETE4']))\n",
    "\n",
    "df.DIABETE4.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carme\\AppData\\Local\\Temp\\ipykernel_14948\\2903463119.py:6: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis(range(len(df)), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302304, 174)\n",
      "(75576, 174)\n",
      "(302304,)\n",
      "(75576,)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(df.columns[0],axis = 1)\n",
    "\n",
    "# remove colums containing NaN values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "df.set_axis(range(len(df)), inplace=True)\n",
    "\n",
    "# removing target('diabetes') from features\n",
    "target = df['DIABETE4']\n",
    "features = df.drop(['DIABETE4'],axis=1)\n",
    "\n",
    "# splitting into training and test data\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Support Vector Machines**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy: 76 % with max_iter = 93\n",
    "\n",
    "-> Dont use, 2. & 3. perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 10\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    svm_predictions = svm_classifier.predict(features_test)\n",
    "    svm_accuracy = accuracy_score(target_test, svm_predictions)\n",
    "\n",
    "    return {'loss': - svm_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' #################################################################################################\n",
    "\n",
    "# max_iter = best['max_iter']\n",
    "# svm_classifier = make_pipeline(StandardScaler(), svm.SVC(max_iter=max_iter)).fit(features_train, target_train)\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "# def make_test_prediction(svm_classifier):\n",
    "#     rand_index = random.randint(0, 32581)\n",
    "#     test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "#     test_groundtruth = target_test.iloc[rand_index]\n",
    "#     prediction = svm_classifier.predict([test_row])\n",
    "#     \n",
    "#     return (prediction, test_groundtruth)\n",
    "\n",
    "# prediction, test_groundtruth = make_test_prediction(svm_classifier)\n",
    "# print (prediction == test_groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Stocastic Gradient Descent**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  88%, with max_iter = 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing max_iter to reach the highest possible Accuracy\n",
    "\n",
    "# MAX_EVALS should be the same as/max the SEARCHSPACE so all possibilities are tried out\n",
    "MAX_EVALS = 15\n",
    "SEARCH_SPACE = [hp.randint('max_iter',100)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(max_iter):\n",
    "    max_iter = max_iter[0]\n",
    "    if max_iter == 0:\n",
    "        return 0\n",
    "    sgd_classifier = make_pipeline(StandardScaler(), SGDClassifier(max_iter=max_iter)).fit(features_train, target_train)\n",
    "    sgd_predictions = sgd_classifier.predict(features_test)\n",
    "    sgd_accuracy = accuracy_score(target_test, sgd_predictions)\n",
    "\n",
    "    return {'loss': - sgd_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = best['max_iter']\n",
    "sgd_classifier = make_pipeline(StandardScaler(), SGDClassifier(max_iter=MAX_ITER)).fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person'  #################################################################################################\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgd_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index]\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgd_classifier.predict([test_row])\n",
    "\n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgd_classifier)\n",
    "print (prediction == test_groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Stocastic Gradient Boosting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Optimizing n_estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of columns containing null values\n",
      "0\n",
      "No. of columns not containing null values\n",
      "175\n",
      "Total no. of columns in the dataframe\n",
      "175\n",
      "No. of rows containing null values\n",
      "0\n",
      "Total no. of rows in the dataframe\n",
      "377880\n",
      "No of rows if all nans dropped\n",
      "377880\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of columns containing null values\")\n",
    "print(len(df.columns[df.isna().any()]))\n",
    "\n",
    "print(\"No. of columns not containing null values\")\n",
    "print(len(df.columns[df.notna().all()]))\n",
    "\n",
    "print(\"Total no. of columns in the dataframe\")\n",
    "print(len(df.columns))\n",
    "\n",
    "print(\"No. of rows containing null values\")\n",
    "null_rows = df.isnull().any(axis=1).sum()\n",
    "print(null_rows)\n",
    "\n",
    "print(\"Total no. of rows in the dataframe\")\n",
    "rows = df.shape[0]\n",
    "print(rows)\n",
    "\n",
    "print(\"No of rows if all nans dropped\")\n",
    "remaining_rows = rows - null_rows\n",
    "print(remaining_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "## Optimizing n_estimators to reach the highest possible accuracy\n",
    "\n",
    "# N_ESTIMATORS should be max the SEARCHSPACE so all possibilities are tried once\n",
    "MAX_EVALS = 1\n",
    "SEARCH_SPACE = [hp.uniformint('n_estimators', 100, 200)]\n",
    "\n",
    "### Optimizaion ##############################################################################################################\n",
    "def cost_function(n_estimators):\n",
    "    n_estimators = n_estimators[0]\n",
    "    if n_estimators == 0:\n",
    "        return 0\n",
    "    sgb_classifier = make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators= n_estimators, learning_rate=0.5, random_state=0)).fit(features_train, target_train)\n",
    "    sgb_predictions = sgb_classifier.predict(features_test)\n",
    "    sgb_accuracy = accuracy_score(target_test, sgb_predictions)\n",
    "    return {'loss': - sgb_accuracy , 'status': STATUS_OK }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(cost_function,\n",
    "    space = SEARCH_SPACE,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = MAX_EVALS, \n",
    "    trials = trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best loss: -0.8988102735569271\n",
    "\n",
    "{'n_estimators': 571.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Training & saving model with optimized n_estimators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = best['n_estimators']\n",
    "\n",
    "sgb_classifier = make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=0.5, random_state=0)).fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_imputed.pickle'\n",
    "\n",
    "pickle.dump(sgb_classifier, open(filename, \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 importing model to predict for one person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgb_classifier = pickle.load(open(filename, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify performance / See false nagatives vs. false positives (ca: 7157 - 1855)\n",
    "\n",
    "predictions = sgb_classifier.predict(features_test)\n",
    "\n",
    "def calc_metrics(predictions, target_test):\n",
    "    prediction_true = false_negative = false_positive = 0\n",
    "\n",
    "    for i in range(0, 87331):\n",
    "        if target_test.iloc[i] == predictions[i]:\n",
    "            prediction_true+= 1\n",
    "        if (target_test.iloc[i] == 1 and predictions[i] == 0):\n",
    "            false_negative +=1\n",
    "        if (target_test.iloc[i] == 0 and predictions[i] == 1):\n",
    "            false_positive +=1\n",
    "    accuracy = 1 - (false_negative + false_positive) / len(predictions)\n",
    "\n",
    "    return (prediction_true, false_negative, false_positive, accuracy)\n",
    "\n",
    "prediction_true, false_negative, false_positive, accuracy = calc_metrics(predictions, target_test)\n",
    "print(prediction_true, false_negative, false_positive, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for one specific 'person' #################################################################################################\n",
    "\n",
    "# taking a random row from the test data to predict a result for:\n",
    "def make_test_prediction(sgb_classifier):\n",
    "    rand_index = random.randint(0, 32581)\n",
    "    test_row = features_test.iloc[rand_index] #.values.flatten().tolist()\n",
    "    test_groundtruth = target_test.iloc[rand_index]\n",
    "    prediction = sgb_classifier.predict([test_row])\n",
    "    \n",
    "    return (prediction, test_groundtruth)\n",
    "\n",
    "prediction, test_groundtruth = make_test_prediction(sgb_classifier)\n",
    "print (prediction)\n",
    "print (test_groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- simple SGB: Best reachable Accuracy:  87.33042784359463%, with max_iter= 74\n",
    "- Using a Pipepline/StandartScaler: Best reachable Accuracy:  100%, with max_iter = 11 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Vizualisations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualisation\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette= \"Accent\")\n",
    "\n",
    "tids = [t['tid'] for t in trials.trials]\n",
    "max_iter = [t['misc']['vals']['n_estimators']for t in trials]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(tids, max_iter)\n",
    "\n",
    "ax.legend(('n_estimators'), loc='lower right')\n",
    "ax.set_ylabel('n_estimators over all trials')\n",
    "ax.set_xlabel('trialIDs')\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "fig.savefig('./visualizations/tested_values.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f891c0ef62455f9f8d0cbb2d117bcba51effc94d210f58e83104cbf88b6bc54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
